from datetime import datetime
import json
import os
from app.core.config import settings
import re
from app.services.dingtalk_service import DingTalkService, get_priority_icon, risk_score_to_priority
from app.core.utils import not_empty
from loguru import logger
from app.services.data_clean_service import DataCleanService


# æœ‰æ•ˆçš„é—®é¢˜ç±»å‹å’Œä¼˜å…ˆçº§
VALID_ISSUE_TYPES = ["ä½¿ç”¨å’¨è¯¢", "é—®é¢˜åé¦ˆ", "äº§å“éœ€æ±‚", "äº§å“ç¼ºé™·"]
VALID_PRIORITIES = ["è¾ƒä½", "æ™®é€š", "ç´§æ€¥", "éå¸¸ç´§æ€¥"]


def normalize_issue_type(issue_type: str | None) -> str:
    """æ ‡å‡†åŒ–é—®é¢˜ç±»å‹ï¼Œç¡®ä¿è¿”å›æœ‰æ•ˆå€¼"""
    if issue_type in VALID_ISSUE_TYPES:
        return issue_type
    return "é—®é¢˜åé¦ˆ"


def normalize_priority(priority: str | None) -> str:
    """æ ‡å‡†åŒ–ä¼˜å…ˆçº§ï¼Œç¡®ä¿è¿”å›æœ‰æ•ˆå€¼"""
    if priority in VALID_PRIORITIES:
        return priority
    return "æ™®é€š"


def markdown_to_plain_text(markdown: str) -> str:
    """
    å°†é’‰é’‰ markdown è½¬æ¢ä¸ºçº¯æ–‡æœ¬æ ¼å¼ï¼ˆå†…å®¹ä¸å˜ï¼Œå»æ‰ markdown ç¬¦å·ï¼‰ã€‚
    """
    if not markdown:
        return ""
    text = markdown
    # å»æ‰ ### æ ‡é¢˜ç¬¦å·
    text = re.sub(r"^###\s*", "", text, flags=re.M)
    # å»æ‰ --- åˆ†éš”çº¿
    text = re.sub(r"^---+\s*$", "", text, flags=re.M)
    # å»æ‰ **åŠ ç²—**
    text = re.sub(r"\*\*([^*]+)\*\*", r"\1", text)
    # å»æ‰ > å¼•ç”¨ç¬¦å·
    text = re.sub(r"^>\s*", "", text, flags=re.M)
    # å»æ‰ * åˆ—è¡¨ç¬¦å·ï¼Œæ›¿æ¢ä¸º â€¢
    text = re.sub(r"^\*\s+", "â€¢  ", text, flags=re.M)
    # å»æ‰ <font color='...'>...</font>
    text = re.sub(r"<font[^>]*>([^<]*)</font>", r"\1", text)
    # å°† [é“¾æ¥æ–‡å­—](url) è½¬ä¸º url
    text = re.sub(r"\[([^\]]*)\]\(([^)]+)\)", r"\2", text)
    # å»æ‰å¤šä½™ç©ºè¡Œï¼ˆè¿ç»­2ä¸ªä»¥ä¸Šæ¢è¡Œå˜æˆ1ä¸ªï¼‰
    text = re.sub(r"\n{3,}", "\n\n", text)
    # å»æ‰è¡Œé¦–å°¾å¤šä½™ç©ºæ ¼
    lines = [line.strip() for line in text.split("\n")]
    # å»æ‰ç©ºè¡Œ
    result_lines = [l for l in lines if l.strip()]
    return "\n".join(result_lines)


def build_ticket_markdown(
    content: dict,
    *,
    issue_type: str | None = None,
    priority: str | None = None,
    phenomenon: str | None = None,
    summary: str | None = None,
    room_name: str | None = None,
    detail_url: str | None = None,
    issue_time: str | None = None,  # æ–°å¢ï¼šé—®é¢˜å‘ç”Ÿæ—¶é—´ï¼ˆå·²æ ¼å¼åŒ–ï¼Œå¦‚ '2/3 09:22'ï¼‰
    # ä»¥ä¸‹å‚æ•°ä¿ç•™å…¼å®¹ï¼ˆæ—§æ¥å£ï¼‰
    risk_score: int = 0,
    issue_type_text: str | None = None,
    severity: str | None = None,
    category_display: str | None = None,
    assignee: str | None = None,
    detail_link: str | None = None,
    draft_id: int | None = None,
    hit_count: int | None = None,
    ticket_url: str | None = None,
    include_ticket_line: bool = True,
) -> str:
    """
    æ„å»ºé’‰é’‰/TB æ¨é€ Markdownï¼ˆæ–°æ ¼å¼ï¼‰
    
    æ ¼å¼ï¼š
    é—®é¢˜ç±»å‹ï¼š{issue_type}
    ã€ä¼˜å…ˆçº§ã€‘{priority_icon} {priority}
    ã€é—®é¢˜ã€‘: {phenomenon}
    ã€æ€»ç»“ã€‘: {summary}
    ã€ğŸ å®¢æˆ·ç¾¤ã€‘: {room_name} | {detail_url}
    ã€æ—¶é—´ã€‘: {issue_time}
    """
    # è·å–å„å­—æ®µå€¼ï¼ˆä¼˜å…ˆä½¿ç”¨æ–°å‚æ•°ï¼Œå¦åˆ™ä» content è·å–ï¼‰
    issue_type_val = issue_type or issue_type_text or content.get("issue_type") or "é—®é¢˜åé¦ˆ"
    issue_type_val = normalize_issue_type(issue_type_val)
    
    # ä¼˜å…ˆçº§ï¼šä¼˜å…ˆä½¿ç”¨æ˜ç¡®ä¼ å…¥çš„ï¼Œå¦åˆ™ä» risk_score è½¬æ¢
    priority_val = priority or content.get("priority")
    if not priority_val:
        rs = risk_score or content.get("risk_score") or 0
        priority_val = risk_score_to_priority(int(rs))
    priority_val = normalize_priority(priority_val)
    
    # é—®é¢˜æè¿°
    phenomenon_val = phenomenon or content.get("phenomenon") or content.get("summary") or content.get("key_sentence") or "æš‚æ— "
    summary_val = summary or content.get("summary") or content.get("key_sentence") or phenomenon_val
    
    # å®¢æˆ·ç¾¤å’Œé“¾æ¥
    room_name_val = room_name or content.get("room_name") or content.get("room_id") or "-"
    detail_url_val = detail_url or detail_link or content.get("detail_url") or f"{settings.INTERNAL_BASE_URL}/api/ui/rooms/{content.get('room_id') or ''}"
    
    # é—®é¢˜æ—¶é—´ï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ï¼Œå¦åˆ™ä» content è·å–ï¼‰
    issue_time_val = issue_time or content.get("issue_time")
    
    # æ„å»ºæ–°æ ¼å¼ Markdown
    return DingTalkService.build_markdown(
        issue_type=issue_type_val,
        priority=priority_val,
        phenomenon=phenomenon_val,
        summary=summary_val,
        room_name=room_name_val,
        detail_url=detail_url_val,
        issue_time=issue_time_val,
    )


def build_tb_note(note_summary: str, detail_url: str) -> str:
    """
    æ„å»º TB ä»»åŠ¡å¤‡æ³¨ï¼ˆç®€åŒ–ç‰ˆï¼Œåªæœ‰ä¸¤è¡Œï¼‰
    
    æ ¼å¼ï¼š
    - åŸç”Ÿæ‘˜è¦ï¼š{note_summary}
    - åŸå£°é“¾æ¥ï¼š{detail_url}
    """
    return f"- åŸç”Ÿæ‘˜è¦ï¼š{note_summary or 'æš‚æ— æ˜ç¡®é—®é¢˜'}\n- åŸå£°é“¾æ¥ï¼š{detail_url or '-'}\n"


def _ensure_full_dingtalk_markdown(content: dict) -> str | None:
    """
    Ensure content['dingtalk_markdown'] is the full DingTalk push markdown.
    Some older drafts may only have partial text in ai_assistant; this rebuilds
    the full markdown from structured fields when missing.
    
    å…³é”®ï¼šå¦‚æœéœ€è¦é‡å»ºï¼Œå¿…é¡»å…ˆä»ç°æœ‰markdownæå–issue_typeï¼Œé¿å…ä¸¢å¤±æ­£ç¡®çš„é—®é¢˜ç±»å‹
    """
    existing = content.get("dingtalk_markdown")
    
    if isinstance(existing, str) and ("é—®é¢˜ç±»å‹" in existing and "ã€ä¼˜å…ˆçº§ã€‘" in existing):
        # å…³é”®ä¿®å¤ï¼šå³ä½¿ä¸é‡å»ºmarkdownï¼Œä¹Ÿè¦ç¡®ä¿content["issue_type"]ä¸markdownä¸€è‡´
        extracted = _extract_issue_type_from_markdown(existing)
        if extracted and extracted != content.get("issue_type"):
            content["issue_type"] = extracted
        return existing

    # éœ€è¦é‡å»º - å…ˆä»ç°æœ‰å†…å®¹æå–issue_typeä»¥ä¿æŒä¸€è‡´æ€§
    if isinstance(existing, str):
        extracted = _extract_issue_type_from_markdown(existing)
        if extracted and not content.get("issue_type"):
            content["issue_type"] = extracted

    try:
        rebuilt = build_ticket_markdown(content)
        content["dingtalk_markdown"] = rebuilt
        return rebuilt
    except Exception as e:
        logger.error(f"[_ensure_full_dingtalk_markdown] é‡å»ºå¤±è´¥: {e}")
        return existing if isinstance(existing, str) else None


def build_customfields_pending(content: dict) -> list[dict]:
    _ensure_full_dingtalk_markdown(content)
    # å…³é”®ï¼šå§‹ç»ˆä» dingtalk_markdown æå– issue_typeï¼Œç¡®ä¿ä¸é’‰é’‰æ¨é€ä¸€è‡´
    # è¿™è§£å†³äº†"é’‰é’‰æ˜¾ç¤ºäº§å“ç¼ºé™·ï¼Œä½†TBé€‰æ‹©é—®é¢˜åé¦ˆ"çš„ä¸ä¸€è‡´é—®é¢˜
    dingtalk_md = content.get("dingtalk_markdown")
    extracted_issue_type = _extract_issue_type_from_markdown(dingtalk_md)
    if extracted_issue_type:
        normalized = normalize_issue_type(extracted_issue_type)
        content["issue_type"] = normalized
    elif not content.get("issue_type"):
        content["issue_type"] = "é—®é¢˜åé¦ˆ"  # é»˜è®¤å€¼
    # AIè¾…åŠ© â†’ é’‰é’‰æ¨é€å†…å®¹è½¬ä¸ºçº¯æ–‡æœ¬ï¼ˆå†…å®¹å®Œå…¨ä¸€è‡´ï¼Œåªå»æ‰ markdown ç¬¦å·ï¼‰
    if not content.get("ai_assistant") or str(content.get("ai_assistant")).strip() in ("", "-"):
        dingtalk_md = content.get("dingtalk_markdown") or ""
        if dingtalk_md:
            content["ai_assistant"] = markdown_to_plain_text(dingtalk_md)
        else:
            # å¦‚æœæ²¡æœ‰ dingtalk_markdownï¼Œä½¿ç”¨ç®€åŒ–æ ¼å¼
            content["ai_assistant"] = build_tb_ai_assistant_text(content)

    mapping_entries = _load_customfield_mapping()
    pending: list[dict] = []
    if mapping_entries:
        for item in mapping_entries:
            cid = item.get("customfieldId") or item.get("id")
            if not cid:
                continue
            value = item.get("value")
            key = item.get("key") or item.get("content_key")
            if value is None and key:
                value = _resolve_content_value(content, key)
            if value is None:
                name = item.get("name")
                key = _guess_content_key_by_name(name or "")
                if key:
                    value = _resolve_content_value(content, key)
            pending.append({"customfieldId": cid, "value": value or "-"})
        content["customfields_pending"] = pending
        return pending

    # If no explicit mapping, try infer from customfield_dict.json by name.
    dict_items = _load_customfield_dict()
    if dict_items:
        for item in dict_items:
            cid = item.get("customfieldId") or item.get("id") or item.get("_id")
            if not cid:
                continue
            key = _guess_content_key_by_name(item.get("name") or "")
            if not key:
                continue
            value = _resolve_content_value(content, key)
            pending.append({"customfieldId": cid, "value": value or "-"})
        if pending:
            content["customfields_pending"] = pending
            return pending

    # Fallback: keep previous order-based mapping if nothing else is available.
    raw_ids = settings.CUSTOM_FIELDS_IDS or ""
    custom_ids = [i.strip() for i in raw_ids.split(",") if i.strip()]
    if not custom_ids:
        return []
    value_pool = [
        content.get("issue_type"),
        content.get("priority"),
        content.get("phenomenon"),
        content.get("summary"),
        content.get("room_name") or content.get("room_id"),
        content.get("client_version"),
        content.get("cbs_version"),
        content.get("image_id"),
    ]
    for idx, cid in enumerate(custom_ids):
        value = value_pool[idx] if idx < len(value_pool) else None
        pending.append({"customfieldId": cid, "value": value or "-"})
    content["customfields_pending"] = pending
    return pending


def build_ai_assistant_text(content: dict) -> str:
    if content.get("dingtalk_markdown"):
        return str(content.get("dingtalk_markdown"))
    parts = []
    if content.get("phenomenon"):
        parts.append(f"ç°è±¡: {content.get('phenomenon')}")
    if content.get("summary"):
        parts.append(f"æ€»ç»“: {content.get('summary')}")
    return "\n".join(parts)


def _extract_issue_type_from_markdown(markdown: str | None) -> str | None:
    if not markdown:
        return None
    
    # æ ¼å¼1ï¼š# æˆ– ### é—®é¢˜ç±»å‹ï¼šxxxï¼ˆæ”¯æŒ ğŸš¨ å‰ç¼€ï¼‰
    match = re.search(r"^#{1,3}\s+(?:ğŸš¨\s*)?é—®é¢˜ç±»å‹ï¼š\s*(.+)$", markdown, flags=re.M)
    if match:
        text = match.group(1).strip()
        if "ã€" in text:
            text = text.split("ã€", 1)[0].strip()
        return text or None
    
    # æ ¼å¼2ï¼šé—®é¢˜ç±»å‹ï¼šxxxï¼ˆæ— æ ‡é¢˜å‰ç¼€ï¼‰
    match = re.search(r"^é—®é¢˜ç±»å‹ï¼š\s*(.+)$", markdown, flags=re.M)
    if match:
        text = match.group(1).strip()
        if "ã€" in text:
            text = text.split("ã€", 1)[0].strip()
        return text or None
    
    # æ ¼å¼3ï¼š**é—®é¢˜ç±»å‹**ï¼šxxxï¼ˆåŠ ç²—æ ¼å¼ï¼‰
    match = re.search(r"^\*\*é—®é¢˜ç±»å‹\*\*ï¼š\s*(.+)$", markdown, flags=re.M)
    if match:
        text = match.group(1).strip()
        if "ã€" in text:
            text = text.split("ã€", 1)[0].strip()
        return text or None
    
    return None


def _extract_phenomenon_from_markdown(markdown: str | None) -> str | None:
    if not markdown:
        return None
    # æ–°æ ¼å¼ï¼šã€é—®é¢˜ã€‘: xxx
    match = re.search(r"ã€é—®é¢˜ã€‘:\s*(.+)", markdown)
    if match:
        return match.group(1).strip()
    # æ—§æ ¼å¼
    match = re.search(r">\s*\*\*ç°è±¡\*\*:\s*(.+)", markdown)
    if match:
        return match.group(1).strip()
    return None


def _resolve_content_value(content: dict, key: str):
    raw_key = key.replace("content.", "")
    return content.get(raw_key)


def _guess_content_key_by_name(name: str) -> str | None:
    if not name:
        return None
    text = name.strip()
    mapping = {
        "é—®é¢˜ç±»å‹": "issue_type",
        "åé¦ˆé—®é¢˜ç±»å‹": "issue_type",
        "ç±»å‹": "issue_type",
        "ä¼˜å…ˆçº§": "priority",
        "ä¸¥é‡åº¦": "severity",
        "ç­‰çº§": "severity",
        "é£é™©": "risk_score",
        "é£é™©æ¦‚ç‡": "risk_score",
        "åˆ†ç±»": "category_short",
        "ç°è±¡": "phenomenon",
        "é—®é¢˜ç°è±¡": "phenomenon",
        "é—®é¢˜": "phenomenon",
        "æ€»ç»“": "summary",
        "å…³é”®å¥": "key_sentence",
        "å…³é”®": "key_sentence",
        "AIè¾…åŠ©": "ai_assistant",
        "æ¦‚æ‹¬": "summary",
        "æ‘˜è¦": "summary",
        "å®¢æˆ·ç¾¤": "room_name",
        "ç¾¤": "room_name",
        "æ ‡ç­¾": "room_name",
        "å®¢æˆ·": "customer",
        "ç¯å¢ƒ": "environment",
        "ç‰ˆæœ¬": "version",
        "å®¢æˆ·ç«¯ç‰ˆæœ¬": "client_version",
        "CBSç‰ˆæœ¬": "cbs_version",
        "é•œåƒID": "image_id",
        "é•œåƒ": "image_id",
        "å¤ç°": "repro_steps",
        "æ­¥éª¤": "repro_steps",
    }
    for keyword, key in mapping.items():
        if keyword in text:
            return key
    return None


def _load_customfield_mapping() -> list[dict]:
    path = settings.CUSTOM_FIELDS_MAPPING_PATH
    if not path or not os.path.exists(path):
        return []
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        if isinstance(data, dict):
            return [{"customfieldId": k, "key": v} for k, v in data.items()]
        if isinstance(data, list):
            return data
    except Exception:
        return []
    return []


def _load_customfield_dict() -> list[dict]:
    path = settings.CUSTOM_FIELDS_DICT_PATH
    if not path or not os.path.exists(path):
        return []
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        if isinstance(data, list):
            return data
    except Exception:
        return []
    return []


def build_customfields_for_create(content: dict) -> list[dict]:
    _ensure_full_dingtalk_markdown(content)
    # Always rebuild to ensure latest rules apply.
    if content.get("ai_assistant") or content.get("dingtalk_markdown"):
        content.pop("customfields_pending", None)
    pending = build_customfields_pending(content)
    # Force write AIè¾…åŠ© into AIè¾…åŠ© field: é’‰é’‰æ¨é€å†…å®¹è½¬ä¸ºçº¯æ–‡æœ¬
    # ä¼˜å…ˆä½¿ç”¨ dingtalk_markdown è½¬æ¢ï¼Œä¿è¯å†…å®¹ä¸é’‰é’‰æ¨é€ä¸€è‡´
    dingtalk_md = content.get("dingtalk_markdown") or ""
    if dingtalk_md:
        ai_assistant_text = markdown_to_plain_text(dingtalk_md)
    else:
        ai_assistant_text = content.get("ai_assistant") or build_tb_ai_assistant_text(content)
    ai_assistant_cf_id = None
    for item in _load_customfield_mapping():
        key = item.get("key") or item.get("content_key")
        if key == "ai_assistant":
            ai_assistant_cf_id = item.get("customfieldId") or item.get("id")
            break
    customfields = []
    for item in pending or []:
        cf_id = item.get("customfieldId")
        value = item.get("value")
        if not cf_id:
            continue
        customfields.append(
            {
                "cfId": cf_id,
                "value": [
                    {
                        "title": str(value) if value is not None else "-",
                        "description": "",
                        "meta": "",
                        "metaString": "",
                    }
                ],
            }
        )
    if ai_assistant_text and ai_assistant_cf_id:
        replaced = False
        for item in customfields:
            if item.get("cfId") == ai_assistant_cf_id:
                item["value"] = [
                    {
                        "title": str(ai_assistant_text),
                        "description": "",
                        "meta": "",
                        "metaString": "",
                    }
                ]
                replaced = True
                break
        if not replaced:
            customfields.append(
                {
                    "cfId": ai_assistant_cf_id,
                    "value": [
                        {
                            "title": str(ai_assistant_text),
                            "description": "",
                            "meta": "",
                            "metaString": "",
                        }
                    ],
                }
            )
    return customfields


def build_tb_ai_assistant_text(content: dict) -> str:
    """
    æ„å»º TB AIè¾…åŠ©å­—æ®µçš„æ–‡æœ¬å†…å®¹ï¼ˆæ–°æ ¼å¼ï¼Œç®€åŒ–ç‰ˆï¼‰
    
    æ ¼å¼ï¼š
    é—®é¢˜ç±»å‹ï¼š{issue_type}
    ã€ä¼˜å…ˆçº§ã€‘{priority_icon} {priority}
    ã€é—®é¢˜ã€‘: {phenomenon}
    ã€æ€»ç»“ã€‘: {summary}
    ã€ğŸ å®¢æˆ·ç¾¤ã€‘: {room_name} | {detail_url}
    """
    issue_type = normalize_issue_type(content.get("issue_type") or "é—®é¢˜åé¦ˆ")
    
    # è·å–ä¼˜å…ˆçº§
    priority = content.get("priority")
    if not priority:
        risk_score = int(content.get("risk_score") or 0)
        priority = risk_score_to_priority(risk_score)
    priority = normalize_priority(priority)
    priority_icon = get_priority_icon(priority)
    
    phenomenon = content.get("phenomenon") if not_empty(content.get("phenomenon")) else (content.get("summary") if not_empty(content.get("summary")) else "æš‚æ— ")
    summary = content.get("summary") if not_empty(content.get("summary")) else (content.get("key_sentence") if not_empty(content.get("key_sentence")) else phenomenon)
    
    room_label = content.get("room_name") or content.get("room_id") or "-"
    detail_url = content.get("detail_url") or f"{settings.INTERNAL_BASE_URL}/api/ui/rooms/{content.get('room_id') or ''}"

    return "\n".join(
        [
            f"é—®é¢˜ç±»å‹ï¼š{issue_type}",
            f"ã€ä¼˜å…ˆçº§ã€‘{priority_icon} {priority}",
            f"ã€é—®é¢˜ã€‘: {phenomenon}",
            f"ã€æ€»ç»“ã€‘: {summary}",
            f"ã€ğŸ å®¢æˆ·ç¾¤ã€‘: {room_label} | {detail_url}",
        ]
    )


def build_customfields_block(content: dict) -> str:
    pending = content.get("customfields_pending")
    if not isinstance(pending, list) or not pending:
        pending = build_customfields_pending(content)
    if not pending:
        return ""
    lines = ["ã€è‡ªå®šä¹‰å­—æ®µï¼ˆé¢„å¡«ï¼‰ã€‘"]
    for item in pending:
        cid = item.get("customfieldId") or "-"
        val = item.get("value") or "-"
        lines.append(f"- cf:{cid} = {val}")
    return "\n".join(lines)


async def generate_ticket_title_llm(phenomenon: str, summary: str, max_len: int = 45) -> str:
    """
    ä½¿ç”¨ LLM ç”Ÿæˆè¯¦ç»†çš„å·¥å•æ ‡é¢˜
    - 30-40å­—
    - å®Œæ•´æè¿°é—®é¢˜
    - ä¸å¸¦"ç”¨æˆ·åé¦ˆ"ç­‰å‰ç¼€
    - ä¸åŒ…å«ç¾¤åå’Œç”¨æˆ·å
    """
    from app.core.llm_factory import get_fast_llm
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser

    prompt = ChatPromptTemplate.from_template("""
ä½ æ˜¯ä¼ä¸šçº§å·¥å•æ ‡é¢˜ç”ŸæˆåŠ©æ‰‹ã€‚æ ¹æ®é—®é¢˜ä¿¡æ¯ï¼Œç”Ÿæˆè¯¦ç»†çš„å·¥å•æ ‡é¢˜ã€‚

ã€é—®é¢˜ç°è±¡ã€‘{phenomenon}
ã€é—®é¢˜æ€»ç»“ã€‘{summary}

ã€æ ‡é¢˜è¦æ±‚ã€‘
- å­—æ•°æ§åˆ¶åœ¨30-40å­—
- å®Œæ•´æè¿°é—®é¢˜ï¼šåŒ…å«é—®é¢˜ç±»å‹ + å…·ä½“ç°è±¡ + å½±å“èŒƒå›´
- åªæè¿°é—®é¢˜æœ¬èº«ï¼Œä¸è¦å¸¦"ç”¨æˆ·åé¦ˆ"ã€"å®¢æˆ·åé¦ˆ"ç­‰å‰ç¼€
- ä¸è¦å¸¦è®¾å¤‡IDï¼ˆACN/ATPå¼€å¤´çš„é•¿ä¸²ï¼‰
- ä¸è¦åŒ…å«ç”¨æˆ·å§“åã€ç¾¤èŠåç§°ã€@æåŠ

ã€ç¤ºä¾‹ã€‘
- è¾“å…¥ï¼šç°è±¡="å…³æœºå¤±è´¥ã€é—ªå±"ï¼Œæ€»ç»“="å¤šå°è®¾å¤‡å‡ºç°å…³æœºå¤±è´¥å’Œé—ªå±é—®é¢˜"
  è¾“å‡ºï¼šå¤šå°è®¾å¤‡å‡ºç°å…³æœºå¤±è´¥å’Œé—ªå±é—®é¢˜ï¼Œå½±å“æ‰¹é‡è®¾å¤‡ç®¡ç†å’Œè¿ç»´æ“ä½œ

- è¾“å…¥ï¼šç°è±¡="ä»£ç†è®¾ç½®å¤±è´¥"ï¼Œæ€»ç»“="æ‰¹é‡è®¾ç½®ä»£ç†æ“ä½œå¤±è´¥ç‡è¾ƒé«˜"
  è¾“å‡ºï¼šæ‰¹é‡ä»£ç†è®¾ç½®æ“ä½œå¤±è´¥ç‡é«˜ï¼Œå¤šæ¬¡é‡è¯•ä»æ— æ³•å®Œæˆé…ç½®ä»»åŠ¡

- è¾“å…¥ï¼šç°è±¡="äº‘æœºæ‰“ä¸å¼€ç”»é¢"ï¼Œæ€»ç»“="äº‘æœºå®ä¾‹æ— æ³•æ­£å¸¸æ˜¾ç¤ºç”»é¢"
  è¾“å‡ºï¼šäº‘æœºå®ä¾‹ç”»é¢æ— æ³•æ­£å¸¸æ˜¾ç¤ºï¼Œç”¨æˆ·æ— æ³•è¿›è¡Œè¿œç¨‹æ“ä½œå’Œä¸šåŠ¡å¤„ç†

ç›´æ¥è¾“å‡ºæ ‡é¢˜ï¼Œä¸è¦åŠ å¼•å·ï¼š
""")

    try:
        chain = prompt | get_fast_llm() | StrOutputParser()
        title = await chain.ainvoke({
            "phenomenon": phenomenon or "",
            "summary": summary or ""
        })
        title = title.strip().strip('"').strip("'")
        # æ¸…ç†å¯èƒ½æ®‹ç•™çš„è®¾å¤‡ID
        title = re.sub(r'\b(ACN|ATP)\d{10,}\b', '', title)
        title = " ".join(title.split())  # æ¸…ç†å¤šä½™ç©ºç™½
        return title[:max_len] if title else (phenomenon or "æœªçŸ¥é—®é¢˜")[:max_len]
    except Exception as e:
        logger.warning(f"LLM ç”Ÿæˆæ ‡é¢˜å¤±è´¥: {e}")
        return (phenomenon or summary or "æœªçŸ¥é—®é¢˜")[:max_len]


async def generate_note_summary_llm(text: str, max_len: int = 30) -> str:
    """
    ä½¿ç”¨ LLM ç”ŸæˆåŸå£°æ‘˜è¦ï¼ˆç”¨äº TB å¤‡æ³¨ï¼‰
    - 30å­—ä»¥å†…
    - åªæè¿°é—®é¢˜æœ¬èº«
    """
    from app.core.llm_factory import get_fast_llm
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser

    # æ§åˆ¶è¾“å…¥é•¿åº¦
    src = " ".join(str(text or "").split())[:800]
    if not src:
        return "æš‚æ— æ˜ç¡®é—®é¢˜"

    prompt = ChatPromptTemplate.from_template("""
ä½ æ˜¯ä¼ä¸šçº§é—®é¢˜æ‘˜è¦åŠ©æ‰‹ã€‚æ ¹æ®èŠå¤©å†…å®¹ï¼Œæå–å¹¶æ€»ç»“æ ¸å¿ƒé—®é¢˜ã€‚

ã€èŠå¤©å†…å®¹ã€‘
{text}

ã€è¦æ±‚ã€‘
- ä¸¥æ ¼30å­—ä»¥å†…
- åªæè¿°é—®é¢˜æœ¬èº«ï¼ˆå¦‚ï¼šç³»ç»Ÿå¡é¡¿ã€æ— æ³•ç™»å½•ã€æ•°æ®ä¸¢å¤±ï¼‰
- ç¦æ­¢åŒ…å«ï¼šè®¾å¤‡IDã€ç”¨æˆ·åã€JSONæ•°æ®ã€å¼•ç”¨æ ¼å¼ã€ç¾¤èŠåç§°
- å¦‚æœå†…å®¹æ— æ³•è¯†åˆ«é—®é¢˜ï¼Œè¾“å‡º"æš‚æ— æ˜ç¡®é—®é¢˜"

ç›´æ¥è¾“å‡ºé—®é¢˜æ‘˜è¦ï¼š
""")

    try:
        chain = prompt | get_fast_llm() | StrOutputParser()
        result = await chain.ainvoke({"text": src})
        result = result.strip()
        return result[:max_len] if result else "æš‚æ— æ˜ç¡®é—®é¢˜"
    except Exception as e:
        logger.warning(f"LLM ç”Ÿæˆæ‘˜è¦å¤±è´¥: {e}")
        return "æš‚æ— æ˜ç¡®é—®é¢˜"


async def extract_versions_and_image_llm(text: str) -> dict:
    """
    ä»å¯¹è¯ä¸­æå–ç‰ˆæœ¬ä¸é•œåƒä¿¡æ¯ï¼ˆç”¨äº TB è‡ªå®šä¹‰å­—æ®µï¼‰
    è¾“å‡ºå­—æ®µï¼š
    - client_version: å®¢æˆ·ç«¯ç‰ˆæœ¬ï¼ˆå¦‚æœªçŸ¥è¾“å‡º "-"ï¼‰
    - cbs_version: CBSç‰ˆæœ¬ï¼ˆå¦‚æœªçŸ¥è¾“å‡º "-"ï¼‰
    - image_id: é•œåƒIDï¼ˆå¦‚æœªçŸ¥è¾“å‡º "-"ï¼‰
    """
    from app.core.llm_factory import get_fast_llm
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser

    # æ§åˆ¶è¾“å…¥é•¿åº¦ï¼Œé¿å…æŠŠæ•´æ®µè¶…é•¿èŠå¤©å¡ç»™æ¨¡å‹
    src = " ".join(str(text or "").split())
    src = src[:800]
    if not src:
        return {"client_version": "-", "cbs_version": "-", "image_id": "-"}

    prompt = ChatPromptTemplate.from_template(
        """
ä½ æ˜¯ä¼ä¸šçº§ä¿¡æ¯æŠ½å–åŠ©æ‰‹ã€‚è¯·ä»èŠå¤©å†…å®¹ä¸­æå–ä»¥ä¸‹å­—æ®µï¼Œå¹¶ä¸¥æ ¼è¾“å‡º JSONï¼ˆä¸è¦è¾“å‡ºå¤šä½™æ–‡å­—ï¼‰ã€‚

ã€èŠå¤©å†…å®¹ã€‘
{text}

ã€å­—æ®µè¦æ±‚ã€‘
- client_versionï¼šåªè¾“å‡ºå®¢æˆ·ç«¯ç‰ˆæœ¬å·ï¼ˆå¦‚ 1.2.3 / v20251211ï¼‰ï¼Œæ²¡æœ‰å°±è¾“å‡º "-"
- cbs_versionï¼šåªè¾“å‡ºCBSç‰ˆæœ¬å·ï¼ˆå¦‚ 20251211_12ï¼‰ï¼Œæ²¡æœ‰å°±è¾“å‡º "-"
- image_idï¼šåªè¾“å‡ºé•œåƒIDï¼ˆå¦‚ img-25121161049ï¼‰ï¼Œæ²¡æœ‰å°±è¾“å‡º "-"
- ç¦æ­¢åŒ…å«äººåã€ç¾¤èŠåã€@ã€ä»¥åŠå¤§æ®µåŸæ–‡

ã€è¯†åˆ«è§„åˆ™ã€‘
- å®¢æˆ·ç«¯ç‰ˆæœ¬ï¼šé€šå¸¸å‡ºç°åœ¨"ç‰ˆæœ¬å·"ã€"å®¢æˆ·ç«¯"ã€"APPç‰ˆæœ¬"é™„è¿‘
- CBSç‰ˆæœ¬ï¼šé€šå¸¸å‡ºç°åœ¨"CBS"ã€"åç«¯ç‰ˆæœ¬"é™„è¿‘ï¼Œæ ¼å¼ä¸ºæ—¥æœŸ_åºå·
- é•œåƒIDï¼šé€šå¸¸ä»¥"img-"å¼€å¤´ï¼Œæˆ–å‡ºç°åœ¨"é•œåƒ"ã€"é•œåƒID"é™„è¿‘

è¾“å‡º JSON ä¾‹å­ï¼š
{{"client_version":"1.2.3","cbs_version":"20251211_12","image_id":"img-25121161049"}}
"""
    )

    try:
        chain = prompt | get_fast_llm() | StrOutputParser()
        raw = await chain.ainvoke({"text": src})
        raw = (raw or "").strip()
        # å°è¯•ä»è¾“å‡ºä¸­æˆªå– JSON
        if "{" in raw and "}" in raw:
            raw = raw[raw.find("{") : raw.rfind("}") + 1]
        data = json.loads(raw)
        return {
            "client_version": str(data.get("client_version") or "-").strip() or "-",
            "cbs_version": str(data.get("cbs_version") or "-").strip() or "-",
            "image_id": str(data.get("image_id") or "-").strip() or "-",
        }
    except Exception:
        return {"client_version": "-", "cbs_version": "-", "image_id": "-"}


VALID_PLATFORMS = ["CBS", "å®¢æˆ·ç«¯", "ROM", "ç§»åŠ¨ç«¯", "å…¶ä»–"]


def normalize_platform(platform: str | None) -> str:
    """æ ‡å‡†åŒ–ç«¯å£åˆ†ç±»ï¼Œç¡®ä¿è¿”å›æœ‰æ•ˆå€¼"""
    if platform in VALID_PLATFORMS:
        return platform
    return "å…¶ä»–"


async def analyze_complete_llm(text: str) -> dict:
    """
    ä½¿ç”¨ LLM ä¸€æ¬¡æ€§åˆ†ææ‰€æœ‰å­—æ®µï¼ˆå®Œæ•´åˆ†æï¼‰
    è¾“å‡ºå­—æ®µï¼š
    - issue_type: é—®é¢˜ç±»å‹
    - priority: ä¼˜å…ˆçº§
    - phenomenon: é—®é¢˜æ¦‚æ‹¬
    - summary: é—®é¢˜æ€»ç»“
    - problem_quote: é—®é¢˜åŸæ–‡å…³é”®å¥ï¼ˆç”¨äºå®šä½é—®é¢˜æ¶ˆæ¯ï¼‰
    - platform: ç«¯å£åˆ†ç±»ï¼ˆCBS/å®¢æˆ·ç«¯/ROM/ç§»åŠ¨ç«¯/å…¶ä»–ï¼‰
    - client_version: å®¢æˆ·ç«¯ç‰ˆæœ¬
    - cbs_version: CBSç‰ˆæœ¬
    - image_id: é•œåƒID
    """
    from app.core.llm_factory import get_fast_llm
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
    from app.prompts.issue_extraction import COMPLETE_ANALYSIS_PROMPT

    # æ§åˆ¶è¾“å…¥é•¿åº¦
    src = " ".join(str(text or "").split())[:1500]
    if not src:
        return {
            "issue_type": "é—®é¢˜åé¦ˆ",
            "priority": "æ™®é€š",
            "phenomenon": "æš‚æ— ",
            "summary": "æš‚æ— ",
            "problem_quote": "",
            "platform": "å…¶ä»–",
            "client_version": "-",
            "cbs_version": "-",
            "image_id": "-",
        }

    prompt = ChatPromptTemplate.from_template(COMPLETE_ANALYSIS_PROMPT)

    try:
        chain = prompt | get_fast_llm() | StrOutputParser()
        raw = await chain.ainvoke({"text": src})
        raw = (raw or "").strip()
        # å°è¯•ä»è¾“å‡ºä¸­æˆªå– JSON
        if "{" in raw and "}" in raw:
            raw = raw[raw.find("{") : raw.rfind("}") + 1]
        data = json.loads(raw)
        return {
            "issue_type": normalize_issue_type(data.get("issue_type")),
            "priority": normalize_priority(data.get("priority")),
            "phenomenon": str(data.get("phenomenon") or "æš‚æ— ")[:30],
            "summary": str(data.get("summary") or "æš‚æ— ")[:50],
            "problem_quote": str(data.get("problem_quote") or "").strip()[:60],
            "first_problem_quote": str(data.get("first_problem_quote") or "").strip()[:60],
            "last_discussion_quote": str(data.get("last_discussion_quote") or "").strip()[:60],
            "platform": normalize_platform(data.get("platform")),
            "client_version": str(data.get("client_version") or "-").strip() or "-",
            "cbs_version": str(data.get("cbs_version") or "-").strip() or "-",
            "image_id": str(data.get("image_id") or "-").strip() or "-",
        }
    except Exception as e:
        logger.warning(f"LLM å®Œæ•´åˆ†æå¤±è´¥: {e}")
        return {
            "issue_type": "é—®é¢˜åé¦ˆ",
            "priority": "æ™®é€š",
            "phenomenon": "æš‚æ— ",
            "summary": "æš‚æ— ",
            "problem_quote": "",
            "platform": "å…¶ä»–",
            "client_version": "-",
            "cbs_version": "-",
            "image_id": "-",
        }


async def pre_judge_has_issue(chat_context: str) -> tuple[bool, str]:
    """
    è½»é‡çº§ LLM é¢„åˆ¤æ–­ï¼šå¯¹è¯ä¸­æ˜¯å¦åŒ…å«æœ‰æ•ˆé—®é¢˜
    
    ç”¨äºåœ¨å®Œæ•´åˆ†æå‰å¿«é€Ÿåˆ¤æ–­æ¶ˆæ¯æ‰¹æ¬¡æ˜¯å¦åŒ…å«éœ€è¦å¤„ç†çš„é—®é¢˜ï¼Œ
    é¿å…å¯¹çº¯é—²èŠ/ç¡®è®¤å›å¤/æ—¥å¸¸é—®å€™ç­‰æ— æ•ˆå†…å®¹è¿›è¡Œå®Œæ•´åˆ†æï¼ŒèŠ‚çœ tokens å’Œæ—¶é—´ã€‚
    
    Args:
        chat_context: å¯¹è¯å†…å®¹ï¼ˆå¤šæ¡æ¶ˆæ¯æ‹¼æ¥ï¼‰
    
    Returns:
        (has_issue: bool, reason: str)
        - has_issue: æ˜¯å¦åŒ…å«æœ‰æ•ˆé—®é¢˜
        - reason: åˆ¤æ–­åŸå› ï¼ˆç®€çŸ­ï¼Œå¦‚"åŠŸèƒ½å¼‚å¸¸"ã€"ç¡®è®¤å›å¤"ç­‰ï¼‰
    """
    from app.core.llm_factory import get_fast_llm
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
    from app.prompts.issue_extraction import get_pre_judge_prompt
    
    # æ§åˆ¶è¾“å…¥é•¿åº¦ï¼ˆé¢„åˆ¤æ–­åªéœ€è¾ƒçŸ­å†…å®¹ï¼Œé™ä½ token æ¶ˆè€—ï¼‰
    src = " ".join(str(chat_context or "").split())[:800]
    if not src:
        return False, "å†…å®¹ä¸ºç©º"
    
    # å¿«é€Ÿè§„åˆ™é¢„åˆ¤ï¼ˆåœ¨è°ƒç”¨ LLM å‰å…ˆç”¨è§„åˆ™è¿‡æ»¤æ˜æ˜¾çš„æƒ…å†µï¼‰
    # å¦‚æœå†…å®¹å¾ˆçŸ­ä¸”æ²¡æœ‰é—®é¢˜ç›¸å…³å…³é”®è¯ï¼Œç›´æ¥åˆ¤å®šæ— é—®é¢˜
    problem_keywords = [
        "æŠ¥é”™", "é”™è¯¯", "å¤±è´¥", "å¼‚å¸¸", "å´©æºƒ", "ç™½å±", "é»‘å±", "é—ªé€€", "å¡", "æ…¢",
        "ä¸èƒ½", "æ— æ³•", "ä¸è¡Œ", "æ‰“ä¸å¼€", "è¿›ä¸å»", "ç”¨ä¸äº†", "æ˜¾ç¤ºä¸", "åŠ è½½ä¸",
        "æ€ä¹ˆ", "å¦‚ä½•", "åœ¨å“ª", "ä¸ºä»€ä¹ˆ", "ä»€ä¹ˆåŸå› ",
        "å¸Œæœ›", "å»ºè®®", "èƒ½ä¸èƒ½", "æœ€å¥½", "éœ€è¦",
        "bug", "Bug", "BUG", "é—®é¢˜", "æ•…éšœ",
    ]
    has_keyword = any(kw in src for kw in problem_keywords)
    
    # å¦‚æœé•¿åº¦è¾ƒçŸ­ä¸”æ— å…³é”®è¯ï¼Œå¤§æ¦‚ç‡æ˜¯å™ªéŸ³
    if len(src) < 50 and not has_keyword:
        return False, "å†…å®¹è¿‡çŸ­"
    
    prompt_template = get_pre_judge_prompt()
    prompt = ChatPromptTemplate.from_template(prompt_template)
    
    try:
        chain = prompt | get_fast_llm() | StrOutputParser()
        raw = await chain.ainvoke({"chat_context": src})
        raw = (raw or "").strip()
        
        # å°è¯•ä»è¾“å‡ºä¸­æˆªå– JSON
        if "{" in raw and "}" in raw:
            raw = raw[raw.find("{") : raw.rfind("}") + 1]
        
        data = json.loads(raw)
        has_issue = bool(data.get("has_issue", False))
        reason = str(data.get("reason", "æœªçŸ¥"))[:20]
        
        return has_issue, reason
        
    except Exception as e:
        logger.warning(f"LLM é¢„åˆ¤æ–­å¤±è´¥: {e}ï¼Œé»˜è®¤æ”¾è¡Œ")
        # é¢„åˆ¤æ–­å¤±è´¥æ—¶é»˜è®¤æ”¾è¡Œï¼Œä¸é˜»å¡æ­£å¸¸æµç¨‹
        return True, "é¢„åˆ¤æ–­å¼‚å¸¸"


def build_ticket_title(content: dict, max_len: int = 45) -> str:
    """
    æ„å»º TB å·¥å•æ ‡é¢˜ï¼šä¼˜å…ˆä½¿ç”¨ LLM ç”Ÿæˆçš„æ ‡é¢˜ï¼ˆ30-40å­—ï¼‰
    """
    # å¦‚æœå·²æœ‰ LLM ç”Ÿæˆçš„æ ‡é¢˜ï¼Œç›´æ¥ä½¿ç”¨
    if content.get("llm_title"):
        return content["llm_title"][:max_len]

    # å¦åˆ™ä½¿ç”¨ phenomenon
    phenomenon = (
        _extract_phenomenon_from_markdown(content.get("dingtalk_markdown"))
        or content.get("phenomenon")
        or content.get("summary")
        or content.get("key_sentence")
        or content.get("description")
        or "æœªæä¾›"
    )
    text = " ".join(str(phenomenon).split())  # æ¸…ç†å¤šä½™ç©ºç™½
    return text[:max_len]


def build_ticket_draft(
    room_id: str,
    summary: str,
    issue_type: str | None = None,
    priority: str | None = None,
    phenomenon: str | None = None,
    room_name: str | None = None,
    detail_url: str | None = None,
    platform: str | None = None,  # ç«¯å£åˆ†ç±»
    client_version: str | None = None,
    cbs_version: str | None = None,
    image_id: str | None = None,
    # ä»¥ä¸‹å‚æ•°ä¿ç•™å…¼å®¹
    category: str | None = None,
    severity: str | None = None,
    risk_score: int = 0,
    raw_text: str | None = None,
    customer: str | None = None,
    key_sentence: str | None = None,
    ai_solution: str | None = None,
    similar_case_solution: str | None = None,
    suggested_reply: str | None = None,
    environment: str | None = None,
    version: str | None = None,
    repro_steps: str | None = None,
    attachments: list[str] | None = None,
) -> dict:
    """
    æ„å»º TicketDraft.contentï¼ˆç»“æ„åŒ– + æ›´é€‚åˆç›´æ¥å»ºå•ï¼‰
    
    æ–°æ ¼å¼å­—æ®µï¼š
    - issue_type: é—®é¢˜ç±»å‹
    - priority: ä¼˜å…ˆçº§
    - phenomenon: é—®é¢˜æ¦‚æ‹¬
    - summary: é—®é¢˜æ€»ç»“
    - platform: ç«¯å£åˆ†ç±»ï¼ˆCBS/å®¢æˆ·ç«¯/ROM/ç§»åŠ¨ç«¯/å…¶ä»–ï¼‰
    - client_version/cbs_version/image_id: ç‰ˆæœ¬ä¿¡æ¯
    """
    # æ ‡å‡†åŒ–å­—æ®µ
    issue_type_val = normalize_issue_type(issue_type)
    if not priority:
        priority = risk_score_to_priority(risk_score)
    priority_val = normalize_priority(priority)
    
    # æ„å»ºæè¿°ï¼ˆç®€åŒ–ç‰ˆï¼‰
    desc_parts: list[str] = []
    if not_empty(phenomenon):
        desc_parts.append(f"ã€é—®é¢˜ç°è±¡ã€‘\n{str(phenomenon).strip()}")
    if not_empty(summary):
        desc_parts.append(f"ã€é—®é¢˜æ‘˜è¦ã€‘\n{str(summary).strip()}")
    if not_empty(raw_text):
        # åŸæ–‡æ”¾æœ€åå¹¶æˆªæ–­ï¼Œé¿å…è¿‡é•¿
        cleaned_raw = DataCleanService.clean_for_llm(str(raw_text))
        if len(cleaned_raw) > 1200:
            cleaned_raw = cleaned_raw[:1200] + "â€¦"
        desc_parts.append(f"ã€å®¢æˆ·åŸæ–‡ã€‘\n{cleaned_raw}")
    description_text = "\n\n".join([p for p in desc_parts if p]) or (raw_text or "")

    return {
        "title": build_ticket_title({"phenomenon": phenomenon, "summary": summary}),
        "room_id": room_id,
        "room_name": room_name,
        "issue_type": issue_type_val,
        "priority": priority_val,
        "phenomenon": phenomenon,
        "summary": summary,
        "platform": normalize_platform(platform),  # ç«¯å£åˆ†ç±»
        "detail_url": detail_url or f"{settings.INTERNAL_BASE_URL}/api/ui/rooms/{room_id}",
        "client_version": client_version or "-",
        "cbs_version": cbs_version or "-",
        "image_id": image_id or "-",
        "description": description_text,
        # ä¿ç•™å…¼å®¹å­—æ®µ
        "customer": customer,
        "category": category,
        "severity": severity,
        "risk_score": risk_score,
        "key_sentence": key_sentence,
        "ai_solution": ai_solution,
        "similar_case_solution": similar_case_solution,
        "suggested_reply": suggested_reply,
        "environment": environment,
        "version": version,
        "repro_steps": repro_steps,
        "attachments": attachments or [],
        "created_at": datetime.utcnow().isoformat(),
        "status": "draft",
    }
