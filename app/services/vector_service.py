# app/services/vector_service.py
import os
import shutil
from typing import List, Dict, Any, Tuple
from loguru import logger
# æ–°ç‰ˆ langchain-chroma çš„å¼•ç”¨æ–¹å¼
from langchain_chroma import Chroma
from langchain_core.documents import Document
from app.core.llm import get_embeddings
from app.services.data_service import _extract_content # å¤ç”¨ä¹‹å‰çš„æ¸…æ´—å‡½æ•°

# å‘é‡åº“/çŸ¥è¯†åº“ç‹¬ç«‹å­˜å‚¨åœ¨é¡¹ç›®æ ¹ç›®å½•
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
VECTOR_DB_DIR = os.path.join(BASE_DIR, "vector_store")
KNOWLEDGE_DB_DIR = os.path.join(BASE_DIR, "knowledge_base")

# é«˜é£é™©å…³é”®è¯ï¼ˆç”¨äºå†å²é£é™©è¯„ä¼°ï¼‰
HIGH_RISK_KEYWORDS = ["å´©æºƒ", "é—ªé€€", "ç™½å±", "æ— æ³•ä½¿ç”¨", "æ•°æ®ä¸¢å¤±", "æŠ•è¯‰", "æŠ¥è­¦", "é€€æ¬¾"]
# ä¸¥é‡ç¨‹åº¦æ˜ å°„
SEVERITY_SCORES = {"S4": 100, "S3": 80, "S2": 60, "S1": 40, "S0": 20}

class VectorKnowledgeBase:
    def __init__(self):
        self.embeddings = get_embeddings()
        # åˆå§‹åŒ– Chroma å®¢æˆ·ç«¯ï¼ˆå‘é‡åº“ & çŸ¥è¯†åº“ï¼‰
        self.chat_store = Chroma(
            collection_name="wecom_chat_history",
            embedding_function=self.embeddings,
            persist_directory=VECTOR_DB_DIR
        )
        self.faq_store = Chroma(
            collection_name="wecom_faq_kb",
            embedding_function=self.embeddings,
            persist_directory=KNOWLEDGE_DB_DIR
        )

    def add_chat_records(self, records: list):
        """
        æ ¸å¿ƒåŠŸèƒ½ï¼šå°† PostgreSQL çš„åŸå§‹è®°å½• -> æ¸…æ´— -> å‘é‡åŒ– -> å­˜å…¥ Chroma
        """
        documents = []
        print(f"ğŸ“¥ å‡†å¤‡å¤„ç† {len(records)} æ¡åŸå§‹è®°å½•...")

        for r in records:
            # 1. æ¸…æ´—æ•°æ® (æå–çº¯æ–‡æœ¬)
            content = _extract_content(r.msgData)
            
            # 2. è¿‡æ»¤æ— æ•ˆæ•°æ® (å¤ªçŸ­çš„æˆ–è€…æ²¡æå–å‡ºæ¥çš„)
            if not content or len(str(content)) < 4:
                continue

            # 3. æ„é€ å…ƒæ•°æ® (Metadata) - æ–¹ä¾¿ä»¥åæº¯æºæ˜¯å“ªä¸ªç¾¤ã€è°è¯´çš„
            meta = {
                "msgid": str(r.msgid),
                "sender": str(r.sender)[-6:] if r.sender else "Unknown", # ç®€å•è„±æ•
                "roomid": str(r.roomid),
                "time": int(r.msgtime)
            }
            
            # 4. å°è£…æˆ Document å¯¹è±¡
            doc = Document(page_content=content, metadata=meta)
            documents.append(doc)
        
        if documents:
            print(f"ğŸš€ æ­£åœ¨å‘é‡åŒ– {len(documents)} æ¡æœ‰æ•ˆæ•°æ® (è¿™å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´)...")
            # æ‰¹é‡å†™å…¥
            self.chat_store.add_documents(documents)
            print(f"âœ… æˆåŠŸå­˜å…¥å‘é‡åº“ï¼å½“å‰åº“ä¸­æ€»æ•°: {self._get_count(self.chat_store)}")
        else:
            print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆæ•°æ®éœ€è¦å­˜å‚¨ã€‚")

    def add_wecom_messages(self, messages: list):
        """
        å°† wecom_messages -> å‘é‡åŒ– -> å­˜å…¥ Chroma
        æ”¯æŒ ORM å¯¹è±¡æˆ– dict è¾“å…¥ã€‚
        """
        documents = []
        for msg in messages:
            if isinstance(msg, dict):
                content = msg.get("content_clean") or msg.get("content_raw") or msg.get("content")
                msg_id = msg.get("msg_id")
                room_id = msg.get("room_id")
                sender_id = msg.get("sender_id")
                msg_time = msg.get("msg_time")
            else:
                content = getattr(msg, "content_clean", None) or getattr(msg, "content_raw", None)
                msg_id = getattr(msg, "msg_id", None)
                room_id = getattr(msg, "room_id", None)
                sender_id = getattr(msg, "sender_id", None)
                msg_time = getattr(msg, "msg_time", None)

            if not content or len(str(content)) < 4:
                continue

            meta = {
                "msgid": str(msg_id) if msg_id is not None else "",
                "sender": str(sender_id)[-6:] if sender_id else "Unknown",
                "roomid": str(room_id) if room_id is not None else "",
                "time": int(getattr(msg_time, "timestamp", lambda: 0)()) if msg_time else 0,
            }
            documents.append(Document(page_content=str(content), metadata=meta))

        if documents:
            self.chat_store.add_documents(documents)

    def search_similar_issues(self, query: str, k=3):
        """
        RAG æ ¸å¿ƒï¼šç»™ä¸€ä¸ªé—®é¢˜ï¼Œæ‰¾å‡ºå†å²ä¸Šæœ€ç›¸ä¼¼çš„ k ä¸ªå¯¹è¯
        """
        print(f"ğŸ” RAG æ£€ç´¢ä¸­: '{query}'")
        try:
            results = self.chat_store.similarity_search(query, k=k)
            return results
        except Exception as e:
            print(f"æ£€ç´¢å¤±è´¥ (å¯èƒ½æ˜¯åº“ä¸ºç©º): {e}")
            return []

    def search_similar_faq(self, query: str, k=3):
        """
        çŸ¥è¯†åº“æ£€ç´¢ï¼šä¼˜å…ˆä» FAQ ä¸­æ‰¾ç›¸ä¼¼é—®é¢˜
        """
        try:
            results = self.faq_store.similarity_search(query, k=k)
            return results
        except Exception as e:
            print(f"FAQ æ£€ç´¢å¤±è´¥ (å¯èƒ½æ˜¯åº“ä¸ºç©º): {e}")
            return []

    def add_faq_items(self, items: list[dict]):
        documents = []
        for item in items:
            content = f"Q: {item.get('question')}\nA: {item.get('answer')}"
            meta = {
                "type": "faq",
                "category_l1": item.get("category_l1"),
                "category_l2": item.get("category_l2"),
            }
            documents.append(Document(page_content=content, metadata=meta))
        if documents:
            self.faq_store.add_documents(documents)

    def search_with_metadata(self, query: str, k: int = 3) -> List[Tuple[Document, float]]:
        """
        RAG æ£€ç´¢å¸¦å…ƒæ•°æ®å’Œç›¸ä¼¼åº¦åˆ†æ•°çš„ç»“æœ
        è¿”å›: [(Document, score), ...]
        """
        try:
            results = self.chat_store.similarity_search_with_score(query, k=k)
            return results
        except Exception as e:
            logger.warning(f"RAG æ£€ç´¢å¤±è´¥ (å¯èƒ½æ˜¯åº“ä¸ºç©º): {e}")
            return []

    def get_historical_severity(self, query: str, k: int = 2) -> Dict[str, Any]:
        """
        æ ¹æ®å†å²ç›¸ä¼¼æ¡ˆä¾‹è¯„ä¼°é£é™©ç­‰çº§
        
        Returns:
            {
                "has_similar": bool,           # æ˜¯å¦æ‰¾åˆ°ç›¸ä¼¼æ¡ˆä¾‹
                "max_severity_score": int,     # å†å²æœ€é«˜ä¸¥é‡ç¨‹åº¦åˆ†æ•° (0-100)
                "has_high_risk": bool,         # æ˜¯å¦åŒ…å«é«˜é£é™©å…³é”®è¯
                "similar_categories": list,    # å†å²ç›¸ä¼¼æ¡ˆä¾‹çš„åˆ†ç±»
                "similar_docs": list,          # ç›¸ä¼¼æ–‡æ¡£åˆ—è¡¨
            }
        """
        result = {
            "has_similar": False,
            "max_severity_score": 0,
            "has_high_risk": False,
            "similar_categories": [],
            "similar_docs": [],
        }
        
        try:
            docs = self.chat_store.similarity_search(query, k=k)
            if not docs:
                return result
            
            result["has_similar"] = True
            result["similar_docs"] = docs
            
            for doc in docs:
                content = doc.page_content
                meta = doc.metadata or {}
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«é«˜é£é™©å…³é”®è¯
                for keyword in HIGH_RISK_KEYWORDS:
                    if keyword in content:
                        result["has_high_risk"] = True
                        break
                
                # æå–åˆ†ç±»ä¿¡æ¯
                if meta.get("category_l1"):
                    cat = f"{meta.get('category_l1')}/{meta.get('category_l2', '')}"
                    if cat not in result["similar_categories"]:
                        result["similar_categories"].append(cat)
                
                # æå–ä¸¥é‡ç¨‹åº¦
                severity = meta.get("severity")
                if severity and severity in SEVERITY_SCORES:
                    score = SEVERITY_SCORES[severity]
                    if score > result["max_severity_score"]:
                        result["max_severity_score"] = score
            
            return result
        except Exception as e:
            logger.warning(f"å†å²é£é™©è¯„ä¼°å¤±è´¥: {e}")
            return result

    def get_historical_categories(self, query: str, k: int = 2) -> List[Dict[str, str]]:
        """
        è·å–å†å²ç›¸ä¼¼æ¡ˆä¾‹çš„åˆ†ç±»ä¿¡æ¯ï¼Œç”¨äºè¾…åŠ©åˆ†ç±»
        
        Returns:
            [{"category_l1": ..., "category_l2": ..., "severity": ..., "issue_type": ...}, ...]
        """
        categories = []
        try:
            docs = self.chat_store.similarity_search(query, k=k)
            for doc in docs:
                meta = doc.metadata or {}
                if meta.get("category_l1") or meta.get("issue_type"):
                    categories.append({
                        "category_l1": meta.get("category_l1", ""),
                        "category_l2": meta.get("category_l2", ""),
                        "severity": meta.get("severity", ""),
                        "issue_type": meta.get("issue_type", ""),
                        "content_preview": doc.page_content[:50] if doc.page_content else "",
                    })
        except Exception as e:
            logger.warning(f"å†å²åˆ†ç±»æ£€ç´¢å¤±è´¥: {e}")
        return categories

    def has_similar_hard_issue(self, query: str, k: int = 2) -> bool:
        """
        æ£€æŸ¥å†å²ä¸­æ˜¯å¦æœ‰ç±»ä¼¼çš„"ç¡¬é—®é¢˜"
        ç”¨äºè¾…åŠ© is_hard_issue åˆ¤æ–­
        """
        try:
            docs = self.chat_store.similarity_search(query, k=k)
            for doc in docs:
                content = doc.page_content
                meta = doc.metadata or {}
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«é«˜é£é™©å…³é”®è¯
                for keyword in HIGH_RISK_KEYWORDS:
                    if keyword in content:
                        return True
                
                # æ£€æŸ¥å†å²ä¸¥é‡ç¨‹åº¦
                severity = meta.get("severity")
                if severity in ["S0", "S1", "S2"]:
                    return True
                
                # æ£€æŸ¥æ˜¯å¦è¢«æ ‡è®°ä¸º bug
                if meta.get("is_bug"):
                    return True
            
            return False
        except Exception as e:
            logger.warning(f"ç¡¬é—®é¢˜æ£€ç´¢å¤±è´¥: {e}")
            return False

    def add_issue_with_metadata(self, content: str, metadata: Dict[str, Any]):
        """
        æ·»åŠ å¸¦æœ‰å®Œæ•´å…ƒæ•°æ®çš„é—®é¢˜åˆ°å‘é‡åº“
        ç”¨äºè®°å½•å¤„ç†è¿‡çš„é—®é¢˜ï¼Œä¾¿äºåç»­ RAG æ£€ç´¢
        """
        if not content or len(content) < 4:
            return
        
        doc = Document(page_content=content, metadata=metadata)
        self.chat_store.add_documents([doc])
        logger.debug(f"å·²æ·»åŠ é—®é¢˜åˆ°å‘é‡åº“: {content[:50]}...")

    def _get_count(self, store):
        # è¿™æ˜¯ä¸€ä¸ªå†…éƒ¨è¾…åŠ©æ–¹æ³•ï¼ŒæŸ¥çœ‹åº“é‡Œæœ‰å¤šå°‘æ¡
        return store._collection.count()

# å•ä¾‹æ¨¡å¼ï¼šå…¨å±€ä½¿ç”¨è¿™ä¸ªå®ä¾‹
vector_kb = VectorKnowledgeBase()